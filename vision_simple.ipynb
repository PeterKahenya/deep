{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision\n",
    "from torchvision import io\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torchmetrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, annotations_file, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = io.read_image(img_path)/255\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59999, 9999)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = CustomImageDataset(\"data/FashionMNIST/train/images/\",\n",
    "                                   \"data/FashionMNIST/train/labels.csv\")\n",
    "                                \n",
    "test_dataset = CustomImageDataset(\"data/FashionMNIST/test/images/\",\n",
    "                                  \"data/FashionMNIST/test/labels.csv\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "len(train_dataset),len(test_dataset)\n",
    "# test_dataset[0][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.1119e-01,  3.3034e-01,  4.2629e-01,  5.6226e-01, -3.9210e-01,\n",
       "         -1.0968e-01,  3.2677e-01, -3.8377e-01,  5.8697e-01,  4.2494e-01],\n",
       "        [ 7.7423e-01,  1.0280e-01, -1.7086e-01,  7.4224e-01, -3.2924e-01,\n",
       "         -6.0679e-01,  8.4842e-02,  2.9762e-01, -2.4459e-01,  3.6022e-01],\n",
       "        [-3.7514e-01,  3.0846e-01, -1.2450e-01, -3.5960e-01, -4.6238e-01,\n",
       "         -7.0972e-01,  3.3950e-01,  3.5772e-02,  1.7466e-01,  8.2516e-02],\n",
       "        [-6.3988e-01,  1.5957e-01,  1.0200e-03, -7.5042e-02, -4.2105e-01,\n",
       "         -1.0169e-01,  5.2685e-01, -9.7499e-01,  3.3933e-01,  1.4153e-01],\n",
       "        [ 5.1027e-01,  5.6917e-01, -1.9771e-01,  1.9321e-01,  8.6391e-02,\n",
       "          3.4502e-01, -5.4847e-01, -6.7587e-01, -1.9903e-01,  1.5493e-01],\n",
       "        [ 1.0977e-01,  1.1207e-01,  2.8547e-01,  7.9483e-01,  6.7805e-01,\n",
       "         -3.0337e-01,  6.1187e-01,  5.2059e-01,  2.3048e-01,  3.4811e-01],\n",
       "        [-1.4491e-01, -3.7375e-03,  1.0268e-01, -3.9782e-01, -5.7825e-01,\n",
       "         -7.1492e-02, -2.8627e-01, -5.4424e-01, -4.5052e-02,  2.1730e-01],\n",
       "        [ 1.5941e-01,  3.8735e-01,  2.4845e-01,  4.6433e-01,  1.0294e+00,\n",
       "         -1.1391e-01,  1.9539e-01,  3.1786e-01,  3.8194e-01,  5.2464e-01],\n",
       "        [-1.8991e-01, -1.2308e-01, -8.6083e-02,  4.2784e-02,  4.7283e-02,\n",
       "         -3.1412e-01,  7.4934e-02, -1.7747e-02, -1.5374e-01,  4.8423e-01],\n",
       "        [ 1.2664e-01,  5.4706e-01,  1.1837e+00,  4.7471e-01,  7.4804e-02,\n",
       "         -1.5363e-01,  7.8250e-01, -2.5793e-01,  9.9585e-01,  3.7152e-01],\n",
       "        [-1.6311e-02, -3.0409e-01,  2.1662e-01, -4.6135e-01, -5.7028e-01,\n",
       "         -9.1273e-01, -3.0237e-01,  6.6715e-01, -3.8580e-01,  2.5876e-01],\n",
       "        [ 8.0324e-02,  1.9641e-01,  3.1755e-01,  1.6318e-01, -5.2025e-02,\n",
       "         -5.5865e-01,  2.5699e-01,  8.4848e-02,  4.0744e-01,  2.4831e-01],\n",
       "        [ 7.6598e-01,  6.5129e-02, -2.2915e-01,  7.4272e-01, -5.6590e-01,\n",
       "         -9.2282e-02,  2.6784e-01, -1.3906e-01,  1.8019e-01,  1.7412e-01],\n",
       "        [ 3.1032e-01,  2.0414e-01, -7.9537e-02,  4.3883e-01, -9.8061e-03,\n",
       "         -5.3789e-01,  3.2826e-01,  1.5791e-01,  2.4583e-01,  5.4783e-01],\n",
       "        [-3.3815e-02, -1.5546e-01, -1.1139e-01,  2.3847e-01, -2.7237e-01,\n",
       "         -6.4740e-01,  2.5945e-01, -5.7283e-02,  6.6756e-02,  2.9385e-01],\n",
       "        [-7.1004e-02,  2.2963e-01,  3.0406e-01, -1.3573e-02, -8.1346e-01,\n",
       "         -6.4996e-01,  4.8306e-02, -8.0237e-01, -1.8372e-01,  3.3909e-01],\n",
       "        [-5.1354e-01,  3.4541e-01,  1.7651e-01, -3.5395e-01,  3.1854e-01,\n",
       "         -1.7685e-01,  3.6891e-01,  3.0602e-01,  4.3593e-01, -2.7249e-02],\n",
       "        [ 2.4455e-01,  4.7716e-01,  3.0284e-01,  1.8629e-01,  3.8251e-02,\n",
       "         -8.6207e-01,  4.4616e-01,  2.2176e-01,  8.6055e-01,  5.8098e-01],\n",
       "        [ 2.0607e-01,  1.8925e-01,  1.7110e-01,  2.7223e-01,  9.8405e-02,\n",
       "         -4.8838e-01,  3.3425e-02, -2.9493e-01,  4.9395e-01,  5.3532e-01],\n",
       "        [ 1.3080e-01,  4.4515e-01,  2.9522e-01,  6.5304e-01,  1.9096e-01,\n",
       "          1.8196e-01,  4.5643e-01, -4.5567e-01, -2.5372e-02,  2.7153e-01],\n",
       "        [ 3.4970e-01, -1.5388e-02, -3.9434e-02,  4.0614e-01,  2.6138e-01,\n",
       "         -2.9775e-01,  1.5634e-01,  4.8457e-01,  7.0453e-03,  3.3321e-01],\n",
       "        [ 1.3337e-01, -1.7637e-01, -4.7144e-01,  5.5752e-01, -4.9359e-01,\n",
       "         -1.2448e-01,  4.4825e-01, -2.0007e-01, -1.9867e-01,  2.5802e-01],\n",
       "        [ 5.9702e-01,  2.1055e-01,  3.2713e-01,  2.4268e-01, -5.4054e-01,\n",
       "          3.8382e-02, -1.4272e-01, -1.3327e-02, -4.4387e-01,  1.2241e-02],\n",
       "        [ 5.1145e-01, -8.9276e-02, -1.7627e-01,  2.3880e-01, -5.4184e-01,\n",
       "         -5.6095e-01, -2.3463e-01, -1.0907e-01, -1.9467e-01,  5.1001e-01],\n",
       "        [ 7.9301e-02,  3.5547e-01,  2.2655e-01,  2.9408e-01,  3.0704e-01,\n",
       "         -3.1584e-01,  4.0453e-01,  5.4937e-01,  2.6960e-01,  1.1189e-01],\n",
       "        [ 1.0034e-01,  3.7208e-02,  3.6240e-03,  1.7209e-01, -4.0474e-01,\n",
       "          1.5043e-01,  7.9120e-02, -9.5666e-01,  4.9282e-01,  1.3602e-01],\n",
       "        [-5.0626e-01,  1.3058e-01,  1.6206e-01, -3.0044e-01, -6.1508e-01,\n",
       "         -1.0962e-01,  3.8401e-01, -2.9560e-01, -1.6436e-01, -3.5691e-02],\n",
       "        [-4.9150e-01,  9.3657e-03,  3.8458e-01,  5.7728e-02,  7.5630e-03,\n",
       "         -1.8509e-01,  5.3125e-01, -4.9736e-01,  5.2730e-01,  3.8378e-01],\n",
       "        [ 1.1603e-01, -3.1181e-01, -5.9658e-01,  1.8186e-01, -8.7936e-01,\n",
       "          2.9254e-01, -1.9150e-01, -9.3476e-01, -4.6787e-01,  2.0577e-01],\n",
       "        [ 9.1372e-01,  5.4522e-01,  6.6950e-01,  5.0253e-01, -3.2679e-01,\n",
       "         -1.7833e-01,  1.0228e-01, -1.2883e-01,  4.9406e-01,  3.0617e-01],\n",
       "        [ 5.5015e-01,  5.4422e-01,  4.3522e-01,  4.1008e-01, -3.5314e-01,\n",
       "         -3.3428e-01,  4.4512e-01, -2.7269e-01,  9.0039e-01,  1.7651e-01],\n",
       "        [ 3.2378e-01, -2.3407e-01, -3.9502e-01,  5.0575e-02, -7.2113e-01,\n",
       "         -1.1501e-01, -5.1379e-01, -2.9476e-01, -6.4111e-01,  2.0492e-01],\n",
       "        [ 2.3133e-01,  4.7298e-01,  2.7635e-01,  3.3772e-01,  2.5379e-01,\n",
       "         -8.2015e-01,  5.4891e-01,  5.6192e-01,  6.2710e-01,  3.1387e-01],\n",
       "        [-2.8272e-01,  1.0665e-02, -3.4905e-01, -5.7371e-03,  3.8685e-02,\n",
       "         -4.3692e-01, -9.8689e-03, -3.1997e-01,  1.4346e-02,  5.3778e-01],\n",
       "        [ 1.8316e-01, -3.8793e-01, -3.0975e-01,  9.5501e-02, -6.1829e-01,\n",
       "         -2.9934e-01, -5.5407e-02,  1.3914e-01, -2.5442e-01,  9.9042e-02],\n",
       "        [ 2.1803e-01,  2.2305e-01, -1.8411e-01,  2.6878e-01, -1.7619e-01,\n",
       "         -3.2181e-01,  1.9469e-01, -3.0368e-01,  3.6024e-01,  2.9349e-01],\n",
       "        [ 2.6149e-01,  5.7313e-01,  5.4691e-01,  1.6861e-01,  6.0949e-02,\n",
       "         -3.1175e-01,  3.3815e-01,  4.0669e-01,  4.1945e-01,  1.2524e-02],\n",
       "        [ 4.7179e-01,  9.2225e-02,  1.8983e-01,  3.2804e-01, -6.6280e-01,\n",
       "         -2.0459e-01,  4.6815e-01,  1.0268e-01,  3.3284e-01,  1.5527e-01],\n",
       "        [ 8.0186e-01,  3.7202e-01,  3.5813e-01,  5.4425e-02, -2.9359e-01,\n",
       "          8.0105e-02, -5.6651e-01, -4.5770e-01,  4.3924e-01,  2.8974e-01],\n",
       "        [ 7.2663e-01,  1.0982e+00,  6.0759e-01,  6.2176e-01,  8.6757e-01,\n",
       "          5.7222e-01,  9.9860e-02,  2.5126e-01,  3.8955e-01, -2.3985e-01],\n",
       "        [-3.2355e-01,  3.7537e-01,  4.5542e-01, -2.5610e-01, -4.6826e-01,\n",
       "         -4.7407e-01,  3.1216e-01, -3.9337e-01,  3.9288e-01,  1.8704e-01],\n",
       "        [ 1.8023e-01, -8.0522e-02,  2.8915e-01,  3.6637e-01, -2.1077e-01,\n",
       "         -6.5572e-01,  2.6170e-01, -3.6630e-01,  4.4155e-01,  8.6180e-01],\n",
       "        [ 2.3769e-01,  2.5620e-01, -1.3942e-01,  5.3213e-01, -1.8629e-01,\n",
       "         -4.6478e-01,  5.0246e-01,  1.4584e-02,  2.6588e-01,  2.1267e-01],\n",
       "        [ 9.0921e-02,  4.8738e-01,  4.0579e-01,  2.4635e-01, -6.1696e-02,\n",
       "          1.0971e-02,  2.9471e-01, -6.2606e-01,  6.9046e-01,  7.3587e-02],\n",
       "        [ 5.0540e-01, -5.1122e-02,  1.2802e-01,  2.4659e-01, -6.8584e-01,\n",
       "         -8.7648e-01,  1.2651e-01, -2.3801e-03,  3.6166e-01,  4.4367e-01],\n",
       "        [ 2.2481e-01,  2.7899e-02,  3.1797e-01,  1.1739e-01, -5.9367e-01,\n",
       "         -9.2980e-01,  3.3038e-01,  1.2543e-01,  2.1682e-01,  7.7425e-01],\n",
       "        [ 3.8679e-01,  1.7636e-01, -2.8957e-01,  2.9675e-01,  7.3349e-02,\n",
       "         -8.5468e-01, -1.3676e-01,  8.1839e-01, -5.4157e-01,  1.1412e-01],\n",
       "        [-5.1627e-02,  3.7413e-01,  5.6874e-01, -2.9507e-01, -8.3192e-01,\n",
       "         -4.6630e-01,  2.2031e-01, -5.2958e-01,  6.6008e-01,  1.5122e-01],\n",
       "        [ 2.3066e-01,  3.1502e-01,  7.2103e-02,  5.3967e-01,  2.5639e-01,\n",
       "          7.6166e-02,  5.0337e-01,  2.7974e-02,  4.3529e-01,  2.1173e-01],\n",
       "        [ 6.4072e-02,  7.3243e-02,  7.3311e-01,  2.1657e-01,  5.8461e-02,\n",
       "          4.9874e-02,  3.4868e-01,  1.7990e-01,  3.3052e-01,  1.2630e-01],\n",
       "        [ 7.4080e-01,  3.2545e-01,  4.4676e-01,  2.0402e-02, -3.0432e-01,\n",
       "         -7.1496e-01, -3.2745e-01,  4.2142e-01,  2.5843e-01,  3.8000e-01],\n",
       "        [ 5.8492e-02,  5.2774e-01,  4.0934e-01,  6.3228e-01,  3.2839e-01,\n",
       "         -2.9679e-01,  6.6218e-01, -1.4330e-01,  5.3020e-01,  1.7954e-01],\n",
       "        [ 3.2845e-01,  1.6781e-01,  7.4277e-02, -1.9481e-01, -7.4178e-01,\n",
       "         -5.7103e-01, -2.5216e-01,  1.3281e-01, -2.7620e-01,  1.1779e-01],\n",
       "        [ 8.0266e-02, -4.6518e-02,  1.0210e-01,  3.7333e-01, -8.2858e-01,\n",
       "          5.8844e-02,  3.0798e-01, -9.9564e-01,  3.6997e-03,  1.8879e-01],\n",
       "        [ 3.7846e-01,  2.1591e-01, -2.9072e-01,  4.7603e-01,  4.7455e-02,\n",
       "         -3.3043e-01,  1.1862e-01, -9.1099e-02,  4.9014e-02,  3.9377e-01],\n",
       "        [ 1.3837e-01,  8.5593e-01,  4.7623e-01,  3.4463e-01,  6.7059e-01,\n",
       "          1.6423e-02,  6.2325e-01,  2.9641e-01,  7.8426e-01,  5.8398e-02],\n",
       "        [-7.1881e-02,  2.7490e-01,  1.1617e-01,  7.8492e-02,  8.0292e-02,\n",
       "         -4.7969e-01,  1.6407e-01,  3.9025e-01, -3.6287e-01,  2.2497e-01],\n",
       "        [-1.1755e-02,  1.5025e-01,  6.1402e-02,  4.4691e-03,  1.6098e-01,\n",
       "         -5.6217e-01,  2.2878e-02,  3.5573e-01,  1.3820e-01,  1.7088e-01],\n",
       "        [ 3.7009e-01,  6.6719e-01,  6.0798e-01,  1.2792e-01, -2.5979e-01,\n",
       "         -5.8201e-01,  4.0439e-01,  2.3140e-01,  7.1143e-01,  2.9769e-01],\n",
       "        [-8.7987e-03,  7.3739e-01,  5.8123e-01, -2.0404e-01,  1.7971e-01,\n",
       "         -6.5346e-02,  7.7161e-02,  1.8252e-01,  3.0649e-01, -1.7701e-01],\n",
       "        [ 4.5478e-01,  5.6041e-01,  7.1973e-02,  2.6294e-01, -2.6907e-01,\n",
       "          7.5638e-03,  1.2425e-01, -1.4333e-01,  2.6804e-02,  1.0819e-01],\n",
       "        [-7.6331e-03, -1.6355e-01, -3.0034e-01,  4.7320e-01, -7.8961e-02,\n",
       "          3.3912e-01,  5.4450e-01, -2.9677e-01,  2.6502e-01,  2.3508e-02],\n",
       "        [ 3.5963e-01,  5.7831e-01,  7.5867e-02,  3.0549e-01,  3.9366e-01,\n",
       "         -3.8787e-01,  3.2828e-01,  4.8926e-01,  4.9607e-01,  1.9228e-01],\n",
       "        [ 4.2556e-01,  2.0922e-01,  6.5778e-01,  3.1766e-01, -8.8124e-01,\n",
       "         -1.0071e-01,  3.8739e-01, -5.6530e-01,  4.3641e-01,  1.0920e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleVisionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=784, out_features=10), # in_features = number of features in a data sample (784 pixels)\n",
    "            nn.Linear(in_features=10, out_features=10),\n",
    "        )\n",
    "    def forward(self,X):\n",
    "        return self.classifier(self.flatten(X))\n",
    "\n",
    "model = SimpleVisionModel()\n",
    "model(torch.randn((64,1,28,28)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "Looked at 0/59999 samples\n",
      "Looked at 25600/59999 samples\n",
      "Looked at 51200/59999 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:13<00:27, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.42361384256879914 | Test loss: 0.43144, Test acc: 85.66%\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "Looked at 0/59999 samples\n",
      "Looked at 25600/59999 samples\n",
      "Looked at 51200/59999 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:28<00:14, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.4174228355542683 | Test loss: 0.44553, Test acc: 84.96%\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "Looked at 0/59999 samples\n",
      "Looked at 25600/59999 samples\n",
      "Looked at 51200/59999 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:43<00:00, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.4167349765867567 | Test loss: 0.43916, Test acc: 85.20%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=0.1)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "accuracy_fn = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "EPOCHS = 3\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "epochs_counts = []\n",
    "training_losses = []\n",
    "testing_losses = []\n",
    "training_accuracies = []\n",
    "testing_accuracies = []\n",
    "for epoch in tqdm.tqdm(range(EPOCHS)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    epochs_counts.append(epoch)\n",
    "    # train\n",
    "    train_loss,train_acc = 0,0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy_fn(y_pred.argmax(dim=1).squeeze(),y) * 100\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    training_losses.append(train_loss)\n",
    "    training_accuracies.append(train_acc)\n",
    "\n",
    "\n",
    "    # test\n",
    "    test_loss, test_acc = 0, 0 \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for (X,y) in test_dataloader:\n",
    "            y_test_pred = model(X)\n",
    "            test_loss += loss_fn(y_test_pred,y).item()\n",
    "            test_acc += accuracy_fn(y_test_pred.argmax(dim=1).squeeze(),y).item() * 100\n",
    "    \n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "    testing_losses.append(test_loss)\n",
    "    testing_accuracies.append(test_acc * 100)\n",
    "\n",
    "    print(f\"\\nTrain loss: {train_loss} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs_counts,training_losses)\n",
    "plt.plot(epochs_counts,testing_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
