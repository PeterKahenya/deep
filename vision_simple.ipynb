{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision\n",
    "from torchvision import io\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torchmetrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, annotations_file, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)/255\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(\"data/FashionMNIST/train/images/\",\n",
    "                                   \"data/FashionMNIST/train/labels.csv\",\n",
    "                                   target_transform=transforms.Lambda(lambda y:torch.zeros(10,dtype=torch.float64).scatter_(0, torch.tensor(6), value=1))\n",
    "                                )\n",
    "test_dataset = CustomImageDataset(\"data/FashionMNIST/test/images/\",\n",
    "                                  \"data/FashionMNIST/test/labels.csv\",\n",
    "                                  target_transform=transforms.Lambda(lambda y:torch.zeros(10,dtype=torch.float64).scatter_(0, torch.tensor(6), value=1))\n",
    "                                 )\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "# train_dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVisionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(28*28,15),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(15,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(20,10)\n",
    "        )\n",
    "    def forward(self,X):\n",
    "        return self.classifier(self.flatten(X))\n",
    "\n",
    "model = SimpleVisionModel()\n",
    "# model(torch.randn((64,1,28,28)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/59999 samples\n",
      "Looked at 25600/59999 samples\n",
      "Looked at 51200/59999 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:18<02:47, 18.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.00003 | Test loss: 0.00000, Test acc: 1.00%\n",
      "\n",
      "Looked at 0/59999 samples\n",
      "Looked at 25600/59999 samples\n",
      "Looked at 51200/59999 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:37<02:32, 19.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.00000 | Test loss: 0.00000, Test acc: 1.00%\n",
      "\n",
      "Looked at 0/59999 samples\n",
      "Looked at 25600/59999 samples\n",
      "Looked at 51200/59999 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:52<01:59, 17.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.00000 | Test loss: 0.00000, Test acc: 1.00%\n",
      "\n",
      "Looked at 0/59999 samples\n",
      "Looked at 25600/59999 samples\n",
      "Looked at 51200/59999 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:08<01:38, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.00000 | Test loss: 0.00000, Test acc: 1.00%\n",
      "\n",
      "Looked at 0/59999 samples\n",
      "Looked at 25600/59999 samples\n",
      "Looked at 51200/59999 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:30<01:33, 18.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.00000 | Test loss: 0.00000, Test acc: 1.00%\n",
      "\n",
      "Looked at 0/59999 samples\n",
      "Looked at 25600/59999 samples\n",
      "Looked at 51200/59999 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:50<01:50, 22.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     36\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39minference_mode():\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mfor\u001b[39;00m (X,y) \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[1;32m     38\u001b[0m         y_test_pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     39\u001b[0m         test_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_fn(y_test_pred,y)\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/training/pytorch_deeplearning/env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/training/pytorch_deeplearning/env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/training/pytorch_deeplearning/env/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/training/pytorch_deeplearning/env/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[125], line 22\u001b[0m, in \u001b[0;36mCustomImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image)\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform:\n\u001b[0;32m---> 22\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_transform(label)\n\u001b[1;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m image, label\n",
      "File \u001b[0;32m~/training/pytorch_deeplearning/env/lib/python3.11/site-packages/torchvision/transforms/transforms.py:486\u001b[0m, in \u001b[0;36mLambda.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m--> 486\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlambd(img)\n",
      "Cell \u001b[0;32mIn[133], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset \u001b[39m=\u001b[39m CustomImageDataset(\u001b[39m\"\u001b[39m\u001b[39mdata/FashionMNIST/train/images/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                    \u001b[39m\"\u001b[39m\u001b[39mdata/FashionMNIST/train/labels.csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                    target_transform\u001b[39m=\u001b[39mtransforms\u001b[39m.\u001b[39mLambda(\u001b[39mlambda\u001b[39;00m y:torch\u001b[39m.\u001b[39mzeros(\u001b[39m10\u001b[39m,dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat64)\u001b[39m.\u001b[39mscatter_(\u001b[39m0\u001b[39m, torch\u001b[39m.\u001b[39mtensor(\u001b[39m6\u001b[39m), value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m      4\u001b[0m                                 )\n\u001b[1;32m      5\u001b[0m test_dataset \u001b[39m=\u001b[39m CustomImageDataset(\u001b[39m\"\u001b[39m\u001b[39mdata/FashionMNIST/test/images/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                                   \u001b[39m\"\u001b[39m\u001b[39mdata/FashionMNIST/test/labels.csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m----> 7\u001b[0m                                   target_transform\u001b[39m=\u001b[39mtransforms\u001b[39m.\u001b[39mLambda(\u001b[39mlambda\u001b[39;00m y:torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m10\u001b[39;49m,dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat64)\u001b[39m.\u001b[39;49mscatter_(\u001b[39m0\u001b[39;49m, torch\u001b[39m.\u001b[39;49mtensor(\u001b[39m6\u001b[39;49m), value\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m      8\u001b[0m                                  )\n\u001b[1;32m     10\u001b[0m train_dataloader \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m test_dataloader \u001b[39m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.1)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "accuracy_fn = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "EPOCHS = 5\n",
    "\n",
    "epochs_counts = []\n",
    "training_losses = []\n",
    "testing_losses = []\n",
    "training_accuracies = []\n",
    "testing_accuracies = []\n",
    "for epoch in tqdm.tqdm(range(EPOCHS)):\n",
    "    epochs_counts.append(epoch)\n",
    "    # train\n",
    "    train_loss,train_acc = 0,0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy_fn(y_pred.argmax(dim=1).squeeze(),y.argmax(dim=1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    training_losses.append(train_loss)\n",
    "    training_accuracies.append(train_acc)\n",
    "\n",
    "\n",
    "    # test\n",
    "    test_loss, test_acc = 0, 0 \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for (X,y) in test_dataloader:\n",
    "            y_test_pred = model(X)\n",
    "            test_loss += loss_fn(y_test_pred,y).item()\n",
    "            test_acc += accuracy_fn(y_test_pred.argmax(dim=1).squeeze(),y.argmax(dim=1)).item()\n",
    "    \n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "    testing_losses.append(test_loss)\n",
    "    testing_accuracies.append(test_acc)\n",
    "\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0df8bc2510>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_counts,training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
